## Comparison of Transfer Learning vs. Active Learning:  

| **Feature**           | **Transfer Learning** | **Active Learning**                                                                                                                                                    |
|----------------------|----------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **Objective** | Reuse knowledge from a related task to improve performance on a new task. | Reduce labeling effort by selecting the most informative samples for training. <br/>(Example of informative sample: a sample whose classification probability is ~0.5) |
| **Data Requirement** | Requires a **large pretrained dataset**; the target dataset can be small. | Starts with a **small labeled dataset** and an **unlabeled dataset**.                                                                                                  |
| **Process** | **Pretraining** on a large dataset → **Fine-tuning** on a smaller dataset. | **Train → Select uncertain/informative samples → Label → Retrain (iterative).**                                                                                        |
| **Dataset Growth** | Fixed dataset size—model learns from pretrained knowledge. | Dataset grows over time as more informative samples are labeled.                                                                                                       |
| **Best for…** | When a **large, pretrained model is available** and the new task is **similar**. | When **labeling is expensive** and only a subset of data should be labeled.                                                                                            |
| **Training Cost** | Pretraining can be expensive, but fine-tuning is relatively cheap. | Requires multiple retraining cycles but reduces overall labeling costs.                                                                                                |
| **Adaptability** | Works well when **source and target tasks are similar**. | More adaptable—actively selects new samples for annotation, improving performance over time.                                                                           |
| **Scalability** | Highly scalable if a good pretrained model exists. | Scales well for problems where labeling costs are high.                                                                                                                |
| **Flexibility** | Limited flexibility—performance depends on similarity between pretraining and target tasks. | Highly flexible—**actively adjusts to changing data distributions**.                                                                                                   |
| **Common Use Cases** | **NLP** (fine-tuning BERT for domain-specific text), **image classification** (using ResNet pretrained on ImageNet for medical imaging). | **Fraud detection** (querying uncertain transactions for human review), **self-driving cars** (selecting rare road conditions for labeling).                           |
| **Example** | Using a **pretrained vision model** (ResNet) for **medical X-ray classification**. | Selecting **ambiguous images** for annotation by human experts in **medical imaging**.                                                                                 |

---