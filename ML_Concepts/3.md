## Comparison of Transfer Learning vs. Active Learning:  

| **Feature**           | **Transfer Learning** | **Active Learning**                                                                                                                                                    |
|----------------------|----------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **Objective** | Reuse knowledge from a related task to improve performance on a new task. | Reduce labeling effort by selecting the most informative samples for training. <br/>(Example of informative sample: a sample whose classification probability is ~0.5) |
| **Data Requirement** | Requires a **large pretrained dataset**; the target dataset can be small. | Starts with a **small labeled dataset** and an **unlabeled dataset**.                                                                                                  |
| **Process** | **Pretraining** on a large dataset → **Fine-tuning** on a smaller dataset. | **Train → Select uncertain/informative samples → Label → Retrain (iterative).**                                                                                        |
| **Dataset Growth** | Fixed dataset size—model learns from pretrained knowledge. | Dataset grows over time as more informative samples are labeled.                                                                                                       |
| **Best for…** | When a **large, pretrained model is available** and the new task is **similar**. | When **labeling is expensive** and only a subset of data should be labeled.                                                                                            |
| **Training Cost** | Pretraining can be expensive, but fine-tuning is relatively cheap. | Requires multiple retraining cycles but reduces overall labeling costs.                                                                                                |
| **Adaptability** | Works well when **source and target tasks are similar**. | More adaptable—actively selects new samples for annotation, improving performance over time.                                                                           |
| **Scalability** | Highly scalable if a good pretrained model exists. | Scales well for problems where labeling costs are high.                                                                                                                |
| **Flexibility** | Limited flexibility—performance depends on similarity between pretraining and target tasks. | Highly flexible—**actively adjusts to changing data distributions**.                                                                                                   |
| **Common Use Cases** | **NLP** (fine-tuning BERT for domain-specific text), **image classification** (using ResNet pretrained on ImageNet for medical imaging). | **Fraud detection** (querying uncertain transactions for human review), **self-driving cars** (selecting rare road conditions for labeling).                           |
| **Example** | Using a **pretrained vision model** (ResNet) for **medical X-ray classification**. | Selecting **ambiguous images** for annotation by human experts in **medical imaging**.                                                                                 |

---

# **Continual Learning**

**Continual Learning (CL)** is the ability of an AI model to learn **incrementally over time**, adapting to new data while 
retaining knowledge from previous tasks. This contrasts with traditional machine learning, where models are typically trained once on a fixed dataset.

It is a good technique to 1) `adapt to distribution shifts`. 2) Adapt to rare events (like black friday in e-commerce)
3) Cold start problem
### **Key Aspects of Continual Learning:**  
1. **Avoiding Catastrophic Forgetting** – When learning new tasks, models tend to overwrite previous knowledge. Techniques like **elastic weight consolidation (EWC)**, **memory replay**, and **progressive networks** help mitigate this.  
2. **Transfer Learning & Knowledge Retention** – Ideally, a model should **leverage past experiences** to improve learning efficiency on new tasks.  
3. **Efficiency & Scalability** – CL enables learning **without retraining from scratch**, making it more efficient for **edge AI, robotics, and real-time applications**.  
4. **Task-Agnostic vs. Task-Aware Learning** – Some methods require knowledge of task boundaries (task-aware), while others learn in a **more autonomous, online manner** (task-agnostic).  

### **Techniques for Continual Learning:**  
- **Regularization-based methods** (EWC, SI) – Prevent drastic weight changes to retain past knowledge.  
- **Replay-based methods** (Experience Replay, Generative Replay) – Store and replay past data to maintain performance.  
- **Architecture-based methods** (Progressive Networks, Dynamic Expansion) – Expand network capacity dynamically to handle new tasks.  

---

### **Continual Learning vs. Online Learning**  

Both **Continual Learning (CL)** and **Online Learning (OL)** deal with **incremental data processing**, but they differ in **objectives, memory retention, and adaptation strategies**.  

| Feature                | **Continual Learning (CL)** | **Online Learning (OL)** |
|------------------------|---------------------------|---------------------------|
| **Goal** | Learn new tasks over time **without forgetting** old knowledge. | Update the model with new data as it arrives, often focusing on immediate adaptation. |
| **Handling Past Knowledge** | Prevents **catastrophic forgetting** (e.g., memory replay, regularization). | Past data may be **discarded**—focus is on adapting to recent changes. |
| **Task Transitions** | Often involves **task sequences**, requiring knowledge retention. | Learns from a continuous data stream without explicitly defined tasks. |
| **Memory Usage** | May use **replay buffers** or **progressive models** to store past knowledge. | Typically operates with **limited or no access** to past data. |
| **Training Mode** | Can be **batch-based or streaming**, focusing on long-term adaptation. | Almost always **streaming-based**, processing data in real-time. |
| **Common Algorithms** | Elastic Weight Consolidation (EWC), Replay-based Methods, Progressive Networks. | Stochastic Gradient Descent (SGD), Adaptive Online Learning, Bandit Algorithms. |
| **Example Use Case** | A **personalized AI assistant** remembering user preferences across multiple sessions. | A **stock price prediction model** updating in real time as new market data arrives. |

### **Analogy**  
- **Continual Learning**: Like a person learning multiple subjects over years, ensuring old knowledge isn't lost.  
- **Online Learning**: Like a stock trader making real-time decisions based on the latest market trends, without explicitly storing past trades.  
