## Sampling (interview Qs)

---

### **Basic Questions**
1. **What is sampling, and why is it important?**  
   - Sampling selects a subset of data to reduce costs, handle imbalances, and improve model performance.

2. **Random vs. stratified sampling?**  
   - Random: Equal chance for all points. Stratified: Maintains class proportions.

3. **Purpose of training, validation, and test sets?**  
   - Training: Model learning. Validation: Hyperparameter tuning. Test: Final evaluation.

4. **What is bootstrapping?**  
   - Resampling with replacement to estimate statistics or build ensembles (e.g., Random Forests).

---

### **Intermediate Questions**
5. **What is SMOTE?**  
   - Generates synthetic samples for minority classes to handle imbalanced data.

6. **Cluster vs. stratified sampling?**  
   - Cluster: Randomly selects entire groups. Stratified: Maintains class proportions.

7. **Curse of dimensionality and sampling?**  
   - High-dimensional data makes sampling harder due to sparsity and complexity.

8. **What is importance sampling?**  
   - Samples based on importance/weight, used in reinforcement learning and Monte Carlo methods.

9. **What is Gibbs sampling?**  
   - MCMC method that samples from multivariate distributions using conditional distributions.

---

### **Advanced Questions**
10. **Handling imbalanced datasets?**  
    - Oversampling (e.g., SMOTE), undersampling, class weights, or collecting more data.

11. **Systematic vs. random sampling?**  
    - Systematic: Regular intervals. Random: Equal chance for all points.

12. **What is adaptive sampling?**  
    - Adjusts sampling based on model performance or data distribution, used in active learning.

13. **What is Latin Hypercube Sampling?**  
    - Divides input space into intervals and samples one point per interval for efficient exploration.

14. **What is reservoir sampling?**  
    - Selects fixed samples from a stream without knowing total dataset size.

---

